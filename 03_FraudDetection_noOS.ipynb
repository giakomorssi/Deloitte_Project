{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6HBuEYSO7YTMHMJ/PbPBa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giakomorssi/Deloitte_Project/blob/main/03_FraudDetection_noOS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Data"
      ],
      "metadata": {
        "id": "t0315A0JjvY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffbsL3U8jkV5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Change Colab runtime to GPU\n",
        "import os\n",
        "os.environ['COLAB_TPU_ADDR'] = ''\n",
        "os.environ['COLAB_GPU_ALLOC'] = '1'\n",
        "os.environ['COLAB_GPU'] = '1'\n",
        "print(\"Runtime switched to GPU\")\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "if not tf.test.gpu_device_name():\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('GPU device found:', tf.test.gpu_device_name())\n",
        "\n",
        "# This code sets the runtime to use the GPU if available\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")\n",
        "\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/University/Deloitte/SupplyChainDataset.csv', encoding = 'latin-1')"
      ],
      "metadata": {
        "id": "aboYVnjYjxh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning"
      ],
      "metadata": {
        "id": "lYRBHmf-j3_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Na and Empty Columns\n",
        "\n",
        "df.drop(['Product Description', 'Order Zipcode', 'Order Profit Per Order', 'Customer Email', 'Customer Password'], axis = 1, inplace = True) \n",
        "df.dropna(inplace = True) #remove 1 missing value"
      ],
      "metadata": {
        "id": "rTjitksTj5vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Category Column"
      ],
      "metadata": {
        "id": "N1wlvoXlj8Mu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **COMPLETE:** The order or transaction has been successfully fulfilled and completed.\n",
        "2. **PENDING**: The order or transaction is still in progress and has not yet been completed.\n",
        "3. **CLOSED**: The order or transaction has been closed or terminated for some reason, such as a return or cancellation.\n",
        "4. **PENDING_PAYMENT**: The order or transaction is awaiting payment before it can be processed.\n",
        "5. **CANCELED**: The order or transaction has been canceled by the customer or the seller for some reason.\n",
        "6. **PROCESSING**: The order or transaction is being processed by the seller or merchant.\n",
        "7. **SUSPECTED_FRAUD**: The order or transaction is under review due to suspected fraudulent activity.\n",
        "8. **ON_HOLD**: The order or transaction has been placed on hold for some reason, such as a delay in shipping or a credit hold.\n",
        "9. **PAYMENT_REVIEW**: The payment for the order or transaction is under review by the payment processor or financial institution."
      ],
      "metadata": {
        "id": "1P3--qOaj_Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular -> Complete, Pending, Pending_Payment, Processing\n",
        "# Suspected -> Closed, Canceled, On_Hold, Payment_Review\n",
        "# Fraud -> Suspected_Fraud\n",
        "\n",
        "# define dictionaries to map status values to categories\n",
        "regular_dict = {'COMPLETE': 'Regular', 'PENDING': 'Regular', 'PENDING_PAYMENT': 'Regular', 'PROCESSING': 'Regular'}\n",
        "suspected_dict = {'CLOSED': 'Suspected', 'CANCELED': 'Suspected', 'ON_HOLD': 'Suspected', 'PAYMENT_REVIEW': 'Suspected'}\n",
        "fraud_dict = {'SUSPECTED_FRAUD': 'Fraud'}\n",
        "\n",
        "# create a function to map status values to categories\n",
        "def map_category(status):\n",
        "    if status in regular_dict:\n",
        "        return regular_dict[status]\n",
        "    elif status in suspected_dict:\n",
        "        return suspected_dict[status]\n",
        "    elif status in fraud_dict:\n",
        "        return fraud_dict[status]\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "# apply the function to the 'status' column to create a new 'category' column\n",
        "df['Category'] = df['Order Status'].apply(map_category)\n",
        "\n",
        "print('Regular: ', len([x for x in df['Category'] if x == 'Regular']), '\\n')\n",
        "print('Suspected: ', len([x for x in df['Category'] if x == 'Suspected']), '\\n')\n",
        "print('Fraud: ', len([x for x in df['Category'] if x == 'Fraud']))"
      ],
      "metadata": {
        "id": "PErUmIXSj-dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding"
      ],
      "metadata": {
        "id": "S_JKQJl9kC5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Type\n",
        "df['Type'] = le.fit_transform(df['Type'])\n",
        "\n",
        "# Delivery Status\n",
        "df['Delivery Status'] = le.fit_transform(df['Delivery Status'])\n",
        "\n",
        "# Customer Segment\n",
        "df['Customer Segment'] = le.fit_transform(df['Customer Segment'])\n",
        "\n",
        "# Order Status\n",
        "df['Order Status'] = le.fit_transform(df['Order Status'])\n",
        "\n",
        "# Shipping Mode\n",
        "df['Shipping Mode'] = le.fit_transform(df['Shipping Mode'])\n",
        "\n",
        "# Category\n",
        "df['Category'] = le.fit_transform(df['Category'])"
      ],
      "metadata": {
        "id": "qaz4tUWZkFKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df.drop(['Category Name', 'Customer City',\n",
        "       'Customer Country', 'Customer Fname', 'Customer Id', 'Customer Lname',\n",
        "       'Customer State',\t'Customer Street', 'Department Name', \n",
        "       'Market', 'Order City', 'Order Country', 'Order Customer Id', 'Order Region',\t\n",
        "       'Order State', 'Product Image',\t'Product Name',\n",
        "       'shipping date (DateOrders)', 'order date (DateOrders)', 'Category Id', 'Customer Zipcode', \n",
        "       'Department Id', 'Latitude',\t'Longitude', 'Order Id',\t'Order Item Cardprod Id',\n",
        "       'Order Item Id', 'Product Card Id', 'Product Category Id'], axis = 1, inplace = True)\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/University/Deloitte/df_number.csv', index = False)"
      ],
      "metadata": {
        "id": "Zn7gWskckHxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split  \n",
        "\n",
        "X = df_nn.drop(['Category'], axis=1) #Not scaled\n",
        "y = df_nn['Category']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, shuffle=True)"
      ],
      "metadata": {
        "id": "eezGwCHSkNB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "s = StandardScaler()\n",
        "\n",
        "X_train = s.fit_transform(X_train)\n",
        "X_test = s.transform(X_test)"
      ],
      "metadata": {
        "id": "o6j623udkPNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "DrsgUBFskMG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Initialize a PCA object\n",
        "pca = PCA()\n",
        "\n",
        "# Fit the PCA object to the data\n",
        "pca.fit(X_train)\n",
        "\n",
        "# Create a scree plot\n",
        "num_components = len(pca.explained_variance_ratio_)\n",
        "plt.plot(np.arange(1, num_components+1), pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
        "plt.title('Scree Plot')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.ylabel('Proportion of Variance Explained')\n",
        "plt.show()\n",
        "\n",
        "# Determine the number of components to keep\n",
        "variance_threshold = 0.95\n",
        "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
        "num_components_to_keep = np.argmax(cumulative_variance_ratio >= variance_threshold) + 1\n",
        "\n",
        "print(f'\\n Number of components to keep: {num_components_to_keep}')\n",
        "\n",
        "# Transform the data using the chosen number of components\n",
        "pca = PCA(n_components=num_components_to_keep)\n",
        "X_train_p = pca.fit_transform(X_train)\n",
        "X_test_p = pca.transform(X_test)"
      ],
      "metadata": {
        "id": "QJk2p_EOkR7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the cumulative variance explained\n",
        "\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "cum = np.insert(cumulative_variance_ratio, 0, 0)\n",
        "ylab = np.insert(np.cumsum(pca.explained_variance_ratio_), 0, 0)\n",
        "\n",
        "plt.plot(cum, 'ro-', linewidth=2)\n",
        "plt.title('Cumulative Variance Explained')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Variance Explained')\n",
        "plt.yticks(ylab)\n",
        "plt.xticks(np.arange(0, 21))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kO_ObeGmkT1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Heatmap loadings\n",
        "fig = plt.figure(figsize=(20, 10))\n",
        "sns.heatmap(pca.components_, cmap='coolwarm', annot=True, cbar=False)\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Principal Components')\n",
        "plt.title('PCA Loadings Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7fLYQwRlkViD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the principal components as vectors in the original feature space\n",
        "pc_vectors = pca.components_\n",
        "\n",
        "# Get the names of the original columns\n",
        "column_names = X.columns\n",
        "\n",
        "# Print the names of the columns chosen as principal components\n",
        "num_pcs = pc_vectors.shape[0]\n",
        "for i in range(num_pcs):\n",
        "    pc_name = f'PC{i+1}'\n",
        "    pc_loadings = pc_vectors[i]\n",
        "    relevant_columns = column_names[np.abs(pc_loadings) >= 0.40]\n",
        "    print(f'{pc_name}:\\n {relevant_columns.tolist()}, \\n {pc_loadings[np.abs(pc_loadings) >= 0.40]} \\n ')"
      ],
      "metadata": {
        "id": "3rjD9okVkXI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "P-NJnauSkf84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "y_train = np.ravel(y_train)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(type(X), type(y))"
      ],
      "metadata": {
        "id": "fE_JYQZykfUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier(class_weight='balanced', max_depth = 4)\n",
        "'''\n",
        " Fraud Recall: 0.9819, std: 0.0139, Under 0.7: 0, []\n",
        " Suspected Recall: 0.5624, std: 0.0093\n",
        " Regular Recall: 0.9887, std: 0.0066\n",
        " Total: 0.8443, std: 0.0074\n",
        "'''"
      ],
      "metadata": {
        "id": "3YIFaGN7km9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "OCrPFvJokpeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix, recall_score\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Standardize the data and split it into training and test sets\n",
        "s = StandardScaler()\n",
        "\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "f1_scores = []\n",
        "accuracy_scores = []\n",
        "fraud_recall = []\n",
        "suspected_recall = []\n",
        "regular_recall = [] \n",
        "low = []\n",
        "avg_conf_matrix = np.zeros((3, 3))\n",
        "\n",
        "for i in range(1, 21):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, shuffle=True)\n",
        "\n",
        "  X_train = s.fit_transform(X_train)\n",
        "  X_test = s.transform(X_test)\n",
        "\n",
        "  # PCA\n",
        "  pca = PCA()\n",
        "  pca.fit(X_train)\n",
        "  cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
        "  num_components_to_keep = np.argmax(cumulative_variance_ratio >= 0.95) + 1\n",
        "  pca = PCA(n_components=num_components_to_keep)\n",
        "  X_train = pca.fit_transform(X_train)\n",
        "  X_test = pca.transform(X_test)\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  recall_scores.append(recall_score(y_test, y_pred, average=None))\n",
        "  fraud_recall.append(recall_score(y_test, y_pred, average=None)[0])\n",
        "  regular_recall.append(recall_score(y_test, y_pred, average=None)[1])\n",
        "  suspected_recall.append(recall_score(y_test, y_pred, average=None)[2])\n",
        "\n",
        "  conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "  avg_conf_matrix += conf_matrix\n",
        "\n",
        "  if i % 20 == 0:\n",
        "      print(f'Iteration: {i}')\n",
        "      print(f'Fraud Recall {round(np.average(fraud_recall), 4)}, {round(np.std(fraud_recall), 4)}')\n",
        "      print(f'Suspected Recall {round(np.average(suspected_recall), 4)}, {round(np.std(suspected_recall), 4)}')\n",
        "      print(f'Regular Recall {round(np.average(regular_recall), 4)}, {round(np.std(regular_recall), 4)}')\n",
        "      print(f'Total Recall {round(np.average(recall_scores), 4)}, {round(np.std(recall_scores), 4)} \\n')\n",
        "\n",
        "  if recalls[0] < 0.7:\n",
        "    low.append(round(recalls[0], 4))\n",
        "  \n",
        "print(f'\\n Fraud Recall: {round(np.average(fraud_recall), 4)}, std: {round(np.std(fraud_recall), 4)}, Under 0.7: {len(low)}, {low}\\n Suspected Recall: {round(np.average(suspected_recall), 4)}, std: {round(np.std(suspected_recall), 4)}\\n Regular Recall: {round(np.average(regular_recall), 4)}, std: {round(np.std(regular_recall), 4)}\\n Total: {round(np.average(recall_scores), 4)}, std: {round(np.std(recall_scores), 4)}')\n",
        "\n",
        "np.set_printoptions(precision=4)\n",
        "avg_conf_matrix /= 20\n",
        "print(\"\\n Average Confusion Matrix:\")\n",
        "print(avg_conf_matrix)\n",
        "\n",
        "print('\\n', model)"
      ],
      "metadata": {
        "id": "YWk3Dt0hkrJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "Ny4famA2ktI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "# define your model and obtain predicted probabilities for each class\n",
        "model = DecisionTreeClassifier(class_weight='balanced', max_depth=4)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "\n",
        "# calculate precision-recall curve for each class\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "prc_auc = dict()\n",
        "for i in range(num_classes):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_pred_prob[:, i])\n",
        "    prc_auc[i] = auc(recall[i], precision[i])\n",
        "\n",
        "# plot the Precision-Recall curve for each class\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "for i in range(num_classes):\n",
        "    ax.plot(recall[i], precision[i], label='Class %d (AUC = %0.2f)' % (i, prc_auc[i]))\n",
        "\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_ylabel('Precision')\n",
        "ax.legend(loc='lower left')\n",
        "ax.set_title('Precision-Recall Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qP6urVBckvDc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}