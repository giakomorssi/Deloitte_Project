{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0YywqR0+zN4WUqinbNAUT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giakomorssi/Deloitte_Project/blob/main/02_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Data"
      ],
      "metadata": {
        "id": "orgvMZprijUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Change Colab runtime to GPU\n",
        "import os\n",
        "os.environ['COLAB_TPU_ADDR'] = ''\n",
        "os.environ['COLAB_GPU_ALLOC'] = '1'\n",
        "os.environ['COLAB_GPU'] = '1'\n",
        "print(\"Runtime switched to GPU\")\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "if not tf.test.gpu_device_name():\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('GPU device found:', tf.test.gpu_device_name())\n",
        "\n",
        "# This code sets the runtime to use the GPU if available\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")\n",
        "\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "3YbdOFcuimXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/University/Deloitte/SupplyChainDataset.csv', encoding = 'latin-1')"
      ],
      "metadata": {
        "id": "LKG4GTnhisz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning the Data"
      ],
      "metadata": {
        "id": "eWw2dp9MeOTe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzGJHtMaeF0i"
      },
      "outputs": [],
      "source": [
        "# Remove Na and Empty Columns\n",
        "\n",
        "df.drop(['Product Description', 'Order Zipcode', 'Order Profit Per Order', 'Customer Email', 'Customer Password', 'Customer Country', 'Customer Id', 'Customer Fname', 'Customer Lname', 'Customer Street', 'Order Country', 'Product Card Id', 'Product Category Id', 'Product Image', 'Customer State', 'shipping date (DateOrders)', 'order date (DateOrders)'], axis = 1, inplace = True) \n",
        "df.dropna(inplace = True) #remove 1 missing value"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding"
      ],
      "metadata": {
        "id": "RbisUTEaeX1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the Category Column"
      ],
      "metadata": {
        "id": "wll6Ic-deZql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define dictionaries to map status values to categories\n",
        "regular_dict = {'COMPLETE': 'Regular', 'PENDING': 'Regular', 'PENDING_PAYMENT': 'Regular', 'PROCESSING': 'Regular'}\n",
        "suspected_dict = {'CLOSED': 'Suspected', 'CANCELED': 'Suspected', 'ON_HOLD': 'Suspected', 'PAYMENT_REVIEW': 'Suspected'}\n",
        "fraud_dict = {'SUSPECTED_FRAUD': 'Fraud'}\n",
        "\n",
        "# create a function to map status values to categories\n",
        "def map_category(status):\n",
        "    if status in regular_dict:\n",
        "        return regular_dict[status]\n",
        "    elif status in suspected_dict:\n",
        "        return suspected_dict[status]\n",
        "    elif status in fraud_dict:\n",
        "        return fraud_dict[status]\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "# apply the function to the 'status' column to create a new 'category' column\n",
        "df['Category'] = df['Order Status'].apply(map_category)"
      ],
      "metadata": {
        "id": "wwdP4SP8eVRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label Encoding"
      ],
      "metadata": {
        "id": "fnVQgjIrefSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Type\n",
        "df['Type'] = le.fit_transform(df['Type'])\n",
        "\n",
        "# Delivery Status\n",
        "df['Delivery Status'] = le.fit_transform(df['Delivery Status'])\n",
        "\n",
        "# Category Name\n",
        "df['Category Name'] = le.fit_transform(df['Category Name'])\n",
        "\n",
        "# Department Name\n",
        "df['Department Name'] = le.fit_transform(df['Department Name'])\n",
        "\n",
        "# Market\n",
        "df['Market'] = le.fit_transform(df['Market'])\n",
        "\n",
        "# Order Status\n",
        "df['Order Status'] = le.fit_transform(df['Order Status'])\n",
        "\n",
        "# Shipping Mode\n",
        "df['Shipping Mode'] = le.fit_transform(df['Shipping Mode'])\n",
        "\n",
        "# Customer Segment\n",
        "df['Customer Segment'] = le.fit_transform(df['Customer Segment'])\n",
        "\n",
        "# Category\n",
        "df['Category'] = le.fit_transform(df['Category'])\n",
        "\n",
        "# Customer City\n",
        "df['Customer City'] = le.fit_transform(df['Customer City'])\n",
        "\n",
        "# Order City\n",
        "df['Order City'] = le.fit_transform(df['Order City'])\n",
        "\n",
        "# Product Name\n",
        "df['Product Name'] = le.fit_transform(df['Product Name'])\n",
        "\n",
        "# Order Region\n",
        "df['Order Region'] = le.fit_transform(df['Order Region'])"
      ],
      "metadata": {
        "id": "Ly4l3rMgedcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "sFjf5jaOe6g7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Data"
      ],
      "metadata": {
        "id": "UL2M1m-rerLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['Days for shipping (real)'], axis = 1)\n",
        "y = df['Days for shipping (real)']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "QHMxOu0xevti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode the remaining columns after the split"
      ],
      "metadata": {
        "id": "LDjGgTeRfDsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "\n",
        "encoder = ce.TargetEncoder(cols=['Order State'])\n",
        "\n",
        "X_train = encoder.fit_transform(X_train, y_train)\n",
        "X_test = encoder.transform(X_test)"
      ],
      "metadata": {
        "id": "lnmxBv-nfHpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing the Model"
      ],
      "metadata": {
        "id": "VQxfil1yfMci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Initialize linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Mean squared error: 0.53"
      ],
      "metadata": {
        "id": "6NiVUR5lfQ-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize the model with 100 trees\n",
        "model = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "# Mean squared error: 0.10"
      ],
      "metadata": {
        "id": "Vjkw8naNfIlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance of the Model"
      ],
      "metadata": {
        "id": "XkFndI3LfUUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import pickle\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained model to make predictions on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate mean squared error on the testing data to evaluate model performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Print the mean squared error\n",
        "print(\"Mean squared error: %.5f\" % mse, \"\\n\")\n",
        "\n",
        "# See if the model is good\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "with open('/content/drive/MyDrive/University/Deloitte/models_lr/lr.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "-Qhmd-F2fO3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Over 100 Splits"
      ],
      "metadata": {
        "id": "B0rf5g3nf4-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix, recall_score\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "\n",
        "within_threshold_mean = []\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "results_lr = pd.DataFrame(columns=['Model', 'MSE Mean', 'MSE Std', 'Within Threshold Mean', 'Within Threshold Std'])\n",
        "\n",
        "mse = []\n",
        "\n",
        "# Test the model\n",
        "\n",
        "with open('/content/drive/MyDrive/University/Deloitte/models_lr/rf.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "for i in range(1, 101):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "  encoder = ce.TargetEncoder(cols=['Order State'])\n",
        "\n",
        "  X_train = encoder.fit_transform(X_train, y_train)\n",
        "  X_test = encoder.transform(X_test)\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "    \n",
        "  mse.append(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "  # Calculate the percentage of predictions within the threshold value\n",
        "\n",
        "  within_threshold_mean.append(sum(abs(y_pred - y_test) <= threshold) / len(y_pred))\n",
        "\n",
        "  if i % 20 == 0:\n",
        "      print(f' \\nIteration: {i} \\n')\n",
        "      print(f'MSE Mean: {np.mean(mse)}')\n",
        "      print(f'MSE Std: {np.std(mse)}')\n",
        "      print(f'Within Threshold Mean: {np.mean(within_threshold_mean)}')\n",
        "      print(f'Within Threshold Std: {np.std(within_threshold_mean)}')"
      ],
      "metadata": {
        "id": "4UE6ZZcbf4Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "K6kMlP9nfeit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "with open('/content/drive/MyDrive/University/Deloitte/models_lr/rf.pkl', 'rb') as f:\n",
        "      model = pickle.load(f)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean squared error: \" , mse, \"\\n\")"
      ],
      "metadata": {
        "id": "p9Ilv4kgff3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution plot\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_palette('colorblind')\n",
        "\n",
        "# Set style for the plot\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# Create a distribution plot\n",
        "sns.kdeplot(y_test, label='Actual', fill=True)\n",
        "sns.kdeplot(y_pred, label='Predicted', fill=True)\n",
        "plt.xlabel('Delivery time')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution Plot')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1ex6Ls0Qfipv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a histogram of the residuals\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set style for the plot\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# Create figure and axis objects\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot histogram with specified number of bins and color\n",
        "sns.histplot(residuals, bins=100, color='green', kde=True, ax=ax)\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Residuals')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Histogram of Residuals')\n",
        "ax.set_xlim((-2, 2))\n",
        "\n",
        "# Remove top and right spines\n",
        "sns.despine()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q7mh9Vu6fmbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 Feature Importances\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "\n",
        "# get the feature importances\n",
        "importances = model.feature_importances_\n",
        "\n",
        "# sort the features by importance\n",
        "sorted_idx = importances.argsort()[::-1]\n",
        "\n",
        "# set style for the plot\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# select the top 10 features\n",
        "top_features = X.columns[sorted_idx][:10]\n",
        "top_importances = importances[sorted_idx][:10]\n",
        "\n",
        "# create a figure and axis objects\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "\n",
        "# create a bar chart of the top 10 features\n",
        "sns.barplot(x=top_features, y=top_importances, ax=ax, color='steelblue')\n",
        "\n",
        "# set x-axis label and rotate labels for readability\n",
        "ax.set_xlabel('Feature', fontsize=14)\n",
        "ax.set_xticklabels(top_features, rotation=90, ha='right', fontsize=10)\n",
        "\n",
        "# set y-axis label and tick labels\n",
        "ax.set_ylabel('Importance Score', fontsize=14)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "# set title\n",
        "ax.set_title('Top 10 Feature Importances', fontsize=16)\n",
        "\n",
        "# remove top and right spines\n",
        "sns.despine()\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qWNnAM3ufrz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the threshold value\n",
        "threshold = 0.5\n",
        "\n",
        "# Get the predicted values\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the percentage of predictions within the threshold value\n",
        "within_threshold = (np.abs(y_pred - y_test) < threshold).mean()\n",
        "\n",
        "# Calculate the percentage of predictions outside the threshold value\n",
        "outside_threshold = 1 - within_threshold\n",
        "\n",
        "# Create a pie chart\n",
        "fig, ax = plt.subplots()\n",
        "labels = ['Within threshold', 'Outside threshold']\n",
        "sizes = [within_threshold, outside_threshold]\n",
        "colors = ['#1f77b4', '#ff7f0e']\n",
        "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "\n",
        "# Add a title\n",
        "plt.title('Percentage of Predictions Within 0.5 Days of Delivery', fontsize=13)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8TNgFDd1fxKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "\n",
        "# Get the residuals\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Create a QQ plot\n",
        "qqplot(residuals, line='s')\n",
        "\n",
        "# Add title and axis labels\n",
        "plt.title('QQ Plot of Residuals')\n",
        "plt.xlabel('Theoretical Quantiles')\n",
        "plt.ylabel('Sample Quantiles')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_GWNxKKJfzqC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}